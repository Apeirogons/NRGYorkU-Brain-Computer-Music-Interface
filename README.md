# NRGYorkU Brain Computer Music Interface

### Goal:
To develop a brain-computer music interface to generate music based on a person's emotions, as determined by real-time EEG classification using an Emotiv kit.

### Requirements:
Python 3.x. Anaconda installation highly recommended. Ability to run Jupyter Notebooks
MATLAB/Octave (???)
Required Python libraries will be added as needed.

### Citations
Currently, the code in this repo consists entirely of [Stefan Erlich's music generation algorithm](https://github.com/stefan-ehrlich/code-algorithmicMusicGenerationSystem) and [Muhammad Nadzeri Munawar's Emotiv classifier](https://github.com/nadzeri/Realtime-EEG-Based-Emotion-Recognition). 

We intend on using the (DEAP dataset)[http://www.eecs.qmul.ac.uk/mmv/datasets/deap/] in the future.

Ehrlich, S. K., Agres, K. R., Guan, C., & Cheng, G. (2019). A closed-loop, music-based brain-computer interface for emotion mediation. PloS one, 14(3), e0213516. URL/DOI: https://doi.org/10.1371/journal.pone.0213516

