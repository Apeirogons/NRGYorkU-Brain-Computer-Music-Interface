{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('MachineLearning': conda)"
  },
  "interpreter": {
   "hash": "04ff9afdc7d1490bf12a0db0e835ff63412e01e124c119117e88b34a3fc5e95d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pyeeg.spectrum import bin_power\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tsfresh\n",
    "import pandas as pd\n",
    "from utils.split import split_features_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things associated with the GAMEEMO dataset\n",
    "electrodes = 'AF3 AF4 F3 F4 F7 F8 FC5 FC6 O1 O2 P7 P8 T7 T8'.split(' ')\n",
    "sample_rate = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(112, 14, 38252)\n"
     ]
    }
   ],
   "source": [
    "# In summary, the resulting features are an array containing raw EEG data split into 5-second intervals. \n",
    "# (dimensionality of n subjects*n trials*slice_amt x n_electrodes x 128*5), which I'll call batch size.\n",
    "# and the labels are an array containing valence and arousal for each 5-second interval.\n",
    "# (dimensionality of n subjects*n trials*slice_amt x 2)\n",
    "eeg_splitted_features = np.load('gameemo_features.npy')\n",
    "eeg_splitted_labels = np.load('gameemo_labels.npy')\n",
    "print(eeg_splitted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_splitted_features, eeg_splitted_labels = split_features_and_labels(eeg_splitted_features, eeg_splitted_labels, sample_rate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are originally scaled between 1 and 5. We transform them between 0 and 1.\n",
    "labels = eeg_splitted_labels[:, -1].astype('int32')"
   ]
  },
  {
   "source": [
    "\n",
    "# Extract power bands; we first flatten the first two dimensions to obtain a 2D array of voltage timeseries, we calculate band power for each electrode separately, then get the electrode dimension back. This gives us a dimensionality of (batch size x n electrodes x n bands)\n",
    "reshaped_features = np.reshape(eeg_splitted_features, [eeg_splitted_features.shape[0]*eeg_splitted_features.shape[1], eeg_splitted_features.shape[2]])\n",
    "extracted_powers = np.asarray([bin_power(X=feature, Band=[0.5, 3, 7, 10, 30], Fs=sample_rate) for feature in reshaped_features])[:, 0, :]\n",
    "extracted_powers = np.reshape(extracted_powers, [eeg_splitted_features.shape[0], eeg_splitted_features.shape[1], extracted_powers.shape[1]])\n",
    "print(extracted_powers.shape)\n",
    "# Then we flatten the last two dimensions, leaving some number of bands per electrode as the final feature for each data point.\n",
    "final_features = np.reshape(extracted_powers, [extracted_powers.shape[0], extracted_powers.shape[1]*extracted_powers.shape[2]])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(33376, 14, 4)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold number 0\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      8056\n",
      "           2       1.00      1.00      1.00      8056\n",
      "           3       1.00      1.00      1.00      8056\n",
      "           4       1.00      1.00      1.00      8057\n",
      "\n",
      "    accuracy                           1.00     32225\n",
      "   macro avg       1.00      1.00      1.00     32225\n",
      "weighted avg       1.00      1.00      1.00     32225\n",
      "\n",
      "Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.66      0.60       288\n",
      "           2       0.55      0.51      0.53       288\n",
      "           3       0.52      0.52      0.52       288\n",
      "           4       0.49      0.43      0.46       287\n",
      "\n",
      "    accuracy                           0.53      1151\n",
      "   macro avg       0.53      0.53      0.52      1151\n",
      "weighted avg       0.53      0.53      0.52      1151\n",
      "\n",
      "[3 1 1 ... 1 2 3]\n",
      "[1 2 3 ... 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# We do k-fold cross validation, meaning that we hold out 10% of the data, train on the other 90%, and evaluate the model performance on the original 10%.\n",
    "# We repeat this process k times. \n",
    "# As we can see, there is some overfitting as the train R^2 is much higher than the test R^2.\n",
    "kf = KFold(n_splits=29, shuffle=False)\n",
    "i = 0\n",
    "\n",
    "all_predictions_arousal = np.zeros((final_features.shape[0], ))\n",
    "for train_index, test_index in kf.split(final_features):\n",
    "    x_train = final_features[train_index]\n",
    "    y_train = labels[train_index]\n",
    "    x_test = final_features[test_index]\n",
    "    y_test = labels[test_index]\n",
    "\n",
    "    xgb = RandomForestClassifier()\n",
    "    xgb.fit(x_train, y_train)\n",
    "    \n",
    "\n",
    "    print('Fold number ' + str(i))\n",
    "    y_pred = xgb.predict(x_train)\n",
    "\n",
    "    print('Train:')\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    print('Test: ')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(y_pred)\n",
    "    print(y_test)\n",
    "    all_predictions_arousal[test_index] = y_pred\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}